{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pointsAboveReplacement(file):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    for i, player in enumerate(data):\n",
    "        if i < (len(data)-1):\n",
    "            data[i].update({\"points_above_replacement\": player[\"togga_score\"] - data[i+1][\"togga_score\"]})   \n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(data, json_data)\n",
    "\n",
    "for position in ['goalies', 'defense', 'midfield', 'forwards']:\n",
    "    for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "        file = 'Data/Sorted_Positions/sorted_%s_%s+%s.json' % (position, year[:4], year[-2:])\n",
    "        pointsAboveReplacement(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "points_above = np.array([(x[\"name\"], x[\"points_above_replacement\"]) for x in data[:-1]])\n",
    "#print(points_above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removed ontarget_scoring_att\n",
    "relevant_forward_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                         'minutes', 'successful_dribbles', 'own_goals', 'interception_total', \n",
    "                         'goals_scored', 'key_passes', 'accurateCrosses_total', 'aerialWon_total', 'assists', \n",
    "                         'points_above_replacement', 'name', 'age', 'ontarget_scoring_att', 'next_year']\n",
    "\n",
    "relevant_midfield_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                          'minutes', 'successful_dribbles', 'own_goals', 'interception_total', 'ontarget_scoring_att',\n",
    "                          'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', 'aerialWon_total', \n",
    "                          'assists', 'points_above_replacement', 'name', 'age', 'next_year']\n",
    "\n",
    "relevant_defense_keys = ['goals_conceded', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total',\n",
    "                         'red_cards', 'minutes', 'successful_dribbles', 'own_goals', 'name', 'ontarget_scoring_att',\n",
    "                         'interception_total', 'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', \n",
    "                         'aerialWon_total', 'assists', 'points_above_replacement', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "relevant_goalie_keys = ['goals_conceded', 'saves', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'red_cards', \n",
    "                        'minutes', 'own_goals', 'interception_total', 'key_passes', 'clean_sheets', 'aerialWon_total', \n",
    "                        'penalties_saved', 'points_above_replacement', 'name', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "def removeExtraStats(file, relevant_keys):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        values = [{key: data[i].get(key)} for key in relevant_keys]\n",
    "        item = dict(pair for d in values for pair in d.items())\n",
    "        new_data.append(item)\n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(new_data, json_data)\n",
    "        \n",
    "for position in ['goalies', 'defense', 'midfield', 'forwards']:\n",
    "    for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "        file = 'Data/Sorted_Positions/sorted_%s_%s+%s.json' % (position, year[:4], year[-2:])\n",
    "        if position == 'goalies':\n",
    "            keys = relevant_goalie_keys\n",
    "        elif position == 'defense':\n",
    "            keys = relevant_defense_keys\n",
    "        elif position == 'midfield':\n",
    "            keys = relevant_midfield_keys\n",
    "        else:\n",
    "            keys = relevant_forward_keys\n",
    "        removeExtraStats(file, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import random\n",
    "\n",
    "def sogRandom(file, maxVal):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    for player in data:\n",
    "        if not player.get(\"ontarget_scoring_att\"):\n",
    "            player[\"ontarget_scoring_att\"] = random.randint(0,maxVal)\n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(data, json_data)\n",
    "\n",
    "for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "    file = 'Data/Sorted_Positions/sorted_defense_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,2)\n",
    "    file = 'Data/Sorted_Positions/sorted_midfield_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,5)\n",
    "    file = 'Data/Sorted_Positions/sorted_forwards_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Sorted_Positions/sorted_forwards_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#print(df)\n",
    "#df.shape has 38 entries\n",
    "\n",
    "with open('Data/Sorted_Positions/sorted_forwards_2015+16.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df2 = pd.DataFrame(data)\n",
    "df2 = df2.dropna(axis=1,how='all')\n",
    "df2 = df2.dropna(axis=0,how='any')\n",
    "\n",
    "df = df.set_index(\"name\")\n",
    "df.index.name = None\n",
    "df2 = df2.set_index(\"name\")\n",
    "df2.index.name = None\n",
    "\n",
    "df3 = df2.add(df)\n",
    "df3 = df3.dropna(axis=1,how='all')\n",
    "df3 = df3.dropna(axis=0,how='any')\n",
    "\n",
    "df3.sort_values('togga_score', 0, False)\n",
    "\n",
    "#df3.shape\n",
    "#df3 has 17 entries\n",
    "\n",
    "# Average age of forwards vs. fantasy points\n",
    "#age_average = df[['age','togga_score']].groupby('age', as_index=False).mean()\n",
    "#age_average.plot(x='age', y='togga_score', figsize=(15,10), grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(pd.DataFrame(df, columns = list(['name', 'togga_score', 'points_above_replacement'])))\n",
    "#print(df[[\"togga_score\", \"points_above_replacement\"]])\n",
    "#df\n",
    "#df[[\"togga_score\", \"points_above_replacement\"]].describe()\n",
    "#df[[\"togga_score\", \"points_above_replacement\"]].corr\n",
    "#df.any()\n",
    "#%matplotlib inline\n",
    "\n",
    "#df.hist(column='togga_score', figsize=(15,10))\n",
    "#df.boxplot(column='togga_score', figsize=(15,20))\n",
    "\n",
    "#is_highly_rated = df['togga_score'] >= 300.0\n",
    "#df[is_highly_rated]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Data/Sorted_Positions/sorted_midfield_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#df has 129 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Data/Sorted_Positions/sorted_defense_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#df has 86 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the one year data for forwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"Data/positional.json\", \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "        \n",
    "forwards = []\n",
    "for player in data['4']:\n",
    "    forwards.append(pd.DataFrame([player['history']['2015/16']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2014/15']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2013/14']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2012/13']]))\n",
    "\n",
    "forwards = pd.concat(forwards)\n",
    "filter = forwards['togga_score'] > 0\n",
    "forwards = forwards[filter]\n",
    "keys = relevant_forward_keys.copy()\n",
    "keys.remove('points_above_replacement')\n",
    "forwards = forwards[keys]\n",
    "forwards = forwards.dropna(axis=1,how='all')\n",
    "forwards = forwards.dropna(axis=0,how='any')\n",
    "\n",
    "forwards = forwards.set_index(\"name\")\n",
    "forwards.index.name = None\n",
    "\n",
    "#forwards.sort_values('togga_score', 0, False).head()\n",
    "\n",
    "\n",
    "\n",
    "#for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.95872239373855\n"
     ]
    }
   ],
   "source": [
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "x_keys.remove('name')\n",
    "X = forwards[x_keys]\n",
    "Y = forwards['next_year']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=324)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_prediction = regressor.predict(X_test)\n",
    "#X_test, y_prediction\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = Y_prediction))\n",
    "print(RMSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.37586659659047\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_prediction = regressor.predict(X_test)\n",
    "#y_prediction\n",
    "#X_train.head()\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box and whisker plots of some of the stats\n",
    "plot_keys = ['togga_score', 'goals_scored', 'assists', 'ontarget_scoring_att', 'aerialWon_total', 'minutes', \n",
    "             'successful_dribbles', 'age', 'next_year']\n",
    "forwards[plot_keys].plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "forwards[plot_keys].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: array([  69. ,  285.5,  130.5,  558. ,  329. ,    0. ,  345.5,  118. ,\n        244.5,  551. ,  427. ,  115. ,   82. ,    6. ,   32. ,  272.5,\n          9. ,  555. ,   94. ,    0. ,    0. ,  174. ,  305.5,   94.5,\n        117.5,  410.5,    0. ,  514. ,    0. ,   73. ,  326. ,  414. ,\n        152. ,  295. ,   86.5,    0. ,  372.5,    0. ,  137. ,  101. ,\n        133. ,   -3. ,    0. ,   15. ,  141.5,   22. ,    9. ,  111. ,\n        445.5,  560. ,   15. ,    0. ,  293. ,    0. ,   15. ,  143.5,\n        290. ,  239.5,  123. ,  410. ,   15. ,  430.5,   30. ,  341. ,\n        433. ,  236. ,    0. ,  141.5,  118. ,  578.5])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-726ea76908b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#print(msg)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0my_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[0;32m   1142\u001b[0m                          order=\"C\")\n\u001b[1;32m-> 1143\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    171\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput', \n\u001b[0;32m    172\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: array([  69. ,  285.5,  130.5,  558. ,  329. ,    0. ,  345.5,  118. ,\n        244.5,  551. ,  427. ,  115. ,   82. ,    6. ,   32. ,  272.5,\n          9. ,  555. ,   94. ,    0. ,    0. ,  174. ,  305.5,   94.5,\n        117.5,  410.5,    0. ,  514. ,    0. ,   73. ,  326. ,  414. ,\n        152. ,  295. ,   86.5,    0. ,  372.5,    0. ,  137. ,  101. ,\n        133. ,   -3. ,    0. ,   15. ,  141.5,   22. ,    9. ,  111. ,\n        445.5,  560. ,   15. ,    0. ,  293. ,    0. ,   15. ,  143.5,\n        290. ,  239.5,  123. ,  410. ,   15. ,  430.5,   30. ,  341. ,\n        433. ,  236. ,    0. ,  141.5,  118. ,  578.5])"
     ]
    }
   ],
   "source": [
    "#array = forwards.values\n",
    "#print(array[0])\n",
    "#print(forwards.head(3))\n",
    "#X = np.asarray(forwards[x_keys])\n",
    "#Y = np.asarray(forwards['next_year'], dtype=float)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=324)\n",
    "#Y_train = list(Y_train.values)\n",
    "#Y_test = list(Y_test.values)\n",
    "#X_train = list(X_train.values)\n",
    "#X_test = list(X_test.values)\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    #kfold = cross_validation.KFold(len(X_train), n_folds=10, random_state=seed)\n",
    "    #cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    #results.append(cv_results)\n",
    "    #names.append(name)\n",
    "    #msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    #print(msg)\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_prediction = regressor.predict(X_test)\n",
    "    RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "    print(RMSE)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
