{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pointsAboveReplacement(file):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    for i, player in enumerate(data):\n",
    "        if i < (len(data)-1):\n",
    "            data[i].update({\"points_above_replacement\": player[\"togga_score\"] - data[i+1][\"togga_score\"]})   \n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(data, json_data)\n",
    "\n",
    "for position in ['goalies', 'defense', 'midfield', 'forwards']:\n",
    "    for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "        file = 'Data/Sorted_Positions/sorted_%s_%s+%s.json' % (position, year[:4], year[-2:])\n",
    "        pointsAboveReplacement(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "points_above = np.array([(x[\"name\"], x[\"points_above_replacement\"]) for x in data[:-1]])\n",
    "#print(points_above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removed ontarget_scoring_att\n",
    "relevant_forward_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                         'minutes', 'successful_dribbles', 'own_goals', 'interception_total', \n",
    "                         'goals_scored', 'key_passes', 'accurateCrosses_total', 'aerialWon_total', 'assists', \n",
    "                         'points_above_replacement', 'name', 'age', 'ontarget_scoring_att', 'next_year']\n",
    "\n",
    "relevant_midfield_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                          'minutes', 'successful_dribbles', 'own_goals', 'interception_total', 'ontarget_scoring_att',\n",
    "                          'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', 'aerialWon_total', \n",
    "                          'assists', 'points_above_replacement', 'name', 'age', 'next_year']\n",
    "\n",
    "relevant_defense_keys = ['goals_conceded', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total',\n",
    "                         'red_cards', 'minutes', 'successful_dribbles', 'own_goals', 'name', 'ontarget_scoring_att',\n",
    "                         'interception_total', 'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', \n",
    "                         'aerialWon_total', 'assists', 'points_above_replacement', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "relevant_goalie_keys = ['goals_conceded', 'saves', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'red_cards', \n",
    "                        'minutes', 'own_goals', 'interception_total', 'key_passes', 'clean_sheets', 'aerialWon_total', \n",
    "                        'penalties_saved', 'points_above_replacement', 'name', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "def removeExtraStats(file, relevant_keys):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        values = [{key: data[i].get(key)} for key in relevant_keys]\n",
    "        item = dict(pair for d in values for pair in d.items())\n",
    "        new_data.append(item)\n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(new_data, json_data)\n",
    "        \n",
    "for position in ['goalies', 'defense', 'midfield', 'forwards']:\n",
    "    for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "        file = 'Data/Sorted_Positions/sorted_%s_%s+%s.json' % (position, year[:4], year[-2:])\n",
    "        if position == 'goalies':\n",
    "            keys = relevant_goalie_keys\n",
    "        elif position == 'defense':\n",
    "            keys = relevant_defense_keys\n",
    "        elif position == 'midfield':\n",
    "            keys = relevant_midfield_keys\n",
    "        else:\n",
    "            keys = relevant_forward_keys\n",
    "        removeExtraStats(file, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import random\n",
    "\n",
    "def sogRandom(file, maxVal):\n",
    "    with open(file, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "    for player in data:\n",
    "        if not player.get(\"ontarget_scoring_att\"):\n",
    "            player[\"ontarget_scoring_att\"] = random.randint(0,maxVal)\n",
    "    with open(file, 'w') as json_data:\n",
    "        json.dump(data, json_data)\n",
    "\n",
    "for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n",
    "    file = 'Data/Sorted_Positions/sorted_defense_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,2)\n",
    "    file = 'Data/Sorted_Positions/sorted_midfield_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,5)\n",
    "    file = 'Data/Sorted_Positions/sorted_forwards_%s+%s.json' % (year[:4], year[-2:])\n",
    "    sogRandom(file,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Sorted_Positions/sorted_forwards_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#print(df)\n",
    "#df.shape has 38 entries\n",
    "\n",
    "with open('Data/Sorted_Positions/sorted_forwards_2015+16.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df2 = pd.DataFrame(data)\n",
    "df2 = df2.dropna(axis=1,how='all')\n",
    "df2 = df2.dropna(axis=0,how='any')\n",
    "\n",
    "df = df.set_index(\"name\")\n",
    "df.index.name = None\n",
    "df2 = df2.set_index(\"name\")\n",
    "df2.index.name = None\n",
    "\n",
    "df3 = df2.add(df)\n",
    "df3 = df3.dropna(axis=1,how='all')\n",
    "df3 = df3.dropna(axis=0,how='any')\n",
    "\n",
    "df3.sort_values('togga_score', 0, False)\n",
    "\n",
    "#df3.shape\n",
    "#df3 has 17 entries\n",
    "\n",
    "# Average age of forwards vs. fantasy points\n",
    "#age_average = df[['age','togga_score']].groupby('age', as_index=False).mean()\n",
    "#age_average.plot(x='age', y='togga_score', figsize=(15,10), grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(pd.DataFrame(df, columns = list(['name', 'togga_score', 'points_above_replacement'])))\n",
    "#print(df[[\"togga_score\", \"points_above_replacement\"]])\n",
    "#df\n",
    "#df[[\"togga_score\", \"points_above_replacement\"]].describe()\n",
    "#df[[\"togga_score\", \"points_above_replacement\"]].corr\n",
    "#df.any()\n",
    "#%matplotlib inline\n",
    "\n",
    "#df.hist(column='togga_score', figsize=(15,10))\n",
    "#df.boxplot(column='togga_score', figsize=(15,20))\n",
    "\n",
    "#is_highly_rated = df['togga_score'] >= 300.0\n",
    "#df[is_highly_rated]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Data/Sorted_Positions/sorted_midfield_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#df has 129 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Data/Sorted_Positions/sorted_defense_2016+17.json', \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(axis=1,how='all')\n",
    "df = df.dropna(axis=0,how='any')\n",
    "\n",
    "#df has 86 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the one year data for forwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"Data/positional.json\", \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "        \n",
    "forwards = []\n",
    "for player in data['4']:\n",
    "    forwards.append(pd.DataFrame([player['history']['2015/16']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2014/15']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2013/14']]))\n",
    "    forwards.append(pd.DataFrame([player['history']['2012/13']]))\n",
    "\n",
    "forwards = pd.concat(forwards)\n",
    "filter = forwards['togga_score'] > 0\n",
    "forwards = forwards[filter]\n",
    "keys = relevant_forward_keys.copy()\n",
    "keys.remove('points_above_replacement')\n",
    "forwards = forwards[keys]\n",
    "forwards = forwards.dropna(axis=1,how='all')\n",
    "forwards = forwards.dropna(axis=0,how='any')\n",
    "\n",
    "forwards = forwards.set_index(\"name\")\n",
    "forwards.index.name = None\n",
    "keys.remove('name')\n",
    "\n",
    "#print(forwards.describe())\n",
    "#forwards.sort_values('togga_score', 0, False).head()\n",
    "\n",
    "\n",
    "\n",
    "#for year in ['2012/13', '2013/14', '2014/15', '2015/16', '2016/17']:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.95872239373855\n"
     ]
    }
   ],
   "source": [
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "X = forwards[x_keys]\n",
    "Y = forwards['next_year']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=324)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_prediction = regressor.predict(X_test)\n",
    "#X_test, y_prediction\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = Y_prediction))\n",
    "print(RMSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.53169281535588\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_prediction = regressor.predict(X_test)\n",
    "#y_prediction\n",
    "#X_train.head()\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# box and whisker plots of some of the stats\n",
    "plot_keys = ['togga_score', 'goals_scored', 'assists', 'ontarget_scoring_att', 'aerialWon_total', 'minutes', \n",
    "             'successful_dribbles', 'age', 'next_year']\n",
    "forwards[plot_keys].plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "forwards[plot_keys].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification ML: Categorization of improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.490000 (0.185023)\n",
      "LDA: 0.546667 (0.178388)\n",
      "KNN: 0.306667 (0.210185)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.680000 (0.214580)\n",
      "NB: 0.546667 (0.178388)\n",
      "SVM: 0.410000 (0.220126)\n"
     ]
    }
   ],
   "source": [
    "forwards[\"category\"] = forwards[\"togga_score\"]\n",
    "for index, row in forwards.iterrows():\n",
    "    if row['next_year'] > 0:\n",
    "        ratio = row['togga_score'] / row['next_year']\n",
    "        if  ratio < 0.5:\n",
    "            val = 0\n",
    "        elif ratio < 0.8:\n",
    "            val = 1\n",
    "        elif ratio < 1.0:\n",
    "            val = 2\n",
    "        elif ratio < 1.2:\n",
    "            val = 3\n",
    "        elif ratio < 1.5:\n",
    "            val = 4\n",
    "        else:\n",
    "            val = 5\n",
    "        #print(ratio,val)\n",
    "    else:\n",
    "        #row[x_keys] = 0\n",
    "        #forwards.drop(index, inplace=True)\n",
    "        val = -1\n",
    "    forwards.set_value(index,'category',val)\n",
    "\n",
    "    \n",
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "x_keys.append(\"category\")\n",
    "filter = forwards['next_year'] > 0\n",
    "forwards = forwards[filter]\n",
    "array = forwards[x_keys].values\n",
    "X = array[:,:-1]\n",
    "Y = array[:,-1].astype(int)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "#print(X.shape)\n",
    "#print(X_train.shape)\n",
    "#print(forwards[x_keys].columns.values)\n",
    "#print([x_keys])\n",
    "\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(len(X_train), n_folds=10, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "def makePredictions(model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "    print(accuracy_score(Y_validation, predictions))\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "    \n",
    "    new_data = []\n",
    "    for player in data['4']:\n",
    "        new_data.append(pd.DataFrame([player['history']['2016/17']]))\n",
    "\n",
    "    new_data = pd.concat(new_data)\n",
    "    filter = new_data['togga_score'] > 0\n",
    "    new_data = new_data[filter]\n",
    "    new_data = new_data.dropna(axis=1,how='all')\n",
    "    new_data = new_data.dropna(axis=0,how='any')\n",
    "    new_data = new_data.set_index(\"name\")\n",
    "    new_data.index.name = None\n",
    "    \n",
    "    new_keys = keys.copy()\n",
    "    new_keys.remove('next_year')\n",
    "    array = new_data[new_keys].values\n",
    "    new_X = array[:,:]\n",
    "    predictions = model.predict(new_X)\n",
    "    for name, pred in zip(new_data.index.values, predictions):\n",
    "        print(name,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "[[1 0 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 1]\n",
      " [1 0 2 1 5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.67      1.00      0.80         2\n",
      "          3       0.33      1.00      0.50         1\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.83      0.56      0.67         9\n",
      "\n",
      "avg / total       0.64      0.60      0.58        15\n",
      "\n",
      "Olivier Giroud 5\n",
      "Callum Wilson 5\n",
      "Benik Afobe 5\n",
      "Sam Vokes 4\n",
      "Andre Gray 5\n",
      "Ashley Barnes 5\n",
      "Michy Batshuayi 5\n",
      "Diego Da Silva Costa 2\n",
      "Romelu Lukaku 2\n",
      "Abel Hernández 5\n",
      "Jamie Vardy 1\n",
      "Shinji Okazaki 5\n",
      "Christian Benteke 2\n",
      "Daniel Sturridge 5\n",
      "Divock Origi 4\n",
      "Sergio Agüero 5\n",
      "Wayne Rooney 5\n",
      "Marcus Rashford 1\n",
      "Zlatan Ibrahimovic 3\n",
      "Cristhian Stuani 5\n",
      "Shane Long 5\n",
      "Peter Crouch 3\n",
      "Fabio Borini 5\n",
      "Jermain Defoe 3\n",
      "Harry Kane 1\n",
      "Vincent Janssen 5\n",
      "Troy Deeney 5\n",
      "Salomón Rondón 5\n",
      "Enner Valencia 5\n",
      "Álvaro Negredo 5\n",
      "Fernando Llorente 5\n",
      "Stefano Okaka 5\n",
      "Islam Slimani 5\n"
     ]
    }
   ],
   "source": [
    "makePredictions(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466666666667\n",
      "[[0 0 0 0 1]\n",
      " [1 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 0 0 0]\n",
      " [3 0 1 0 5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.50      0.50      0.50         2\n",
      "          3       0.50      1.00      0.67         1\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.83      0.56      0.67         9\n",
      "\n",
      "avg / total       0.60      0.47      0.51        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivier Giroud 5\n",
      "Callum Wilson 5\n",
      "Benik Afobe 3\n",
      "Sam Vokes 3\n",
      "Andre Gray 5\n",
      "Ashley Barnes 5\n",
      "Michy Batshuayi 5\n",
      "Diego Da Silva Costa 2\n",
      "Romelu Lukaku 2\n",
      "Abel Hernández 3\n",
      "Jamie Vardy 5\n",
      "Shinji Okazaki 5\n",
      "Christian Benteke 4\n",
      "Daniel Sturridge 5\n",
      "Divock Origi 2\n",
      "Sergio Agüero 4\n",
      "Wayne Rooney 5\n",
      "Marcus Rashford 2\n",
      "Zlatan Ibrahimovic 5\n",
      "Cristhian Stuani 5\n",
      "Shane Long 3\n",
      "Peter Crouch 3\n",
      "Fabio Borini 5\n",
      "Jermain Defoe 5\n",
      "Harry Kane 1\n",
      "Vincent Janssen 1\n",
      "Troy Deeney 4\n",
      "Salomón Rondón 2\n",
      "Enner Valencia 5\n",
      "Álvaro Negredo 5\n",
      "Fernando Llorente 5\n",
      "Stefano Okaka 4\n",
      "Islam Slimani 5\n"
     ]
    }
   ],
   "source": [
    "makePredictions(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733333333333\n",
      "[[1 0 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 1]\n",
      " [3 0 0 0 6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      1.00      0.40         1\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.50      0.67         2\n",
      "          5       0.86      0.67      0.75         9\n",
      "\n",
      "avg / total       0.86      0.73      0.77        15\n",
      "\n",
      "Olivier Giroud 5\n",
      "Callum Wilson 5\n",
      "Benik Afobe 5\n",
      "Sam Vokes 5\n",
      "Andre Gray 5\n",
      "Ashley Barnes 4\n",
      "Michy Batshuayi 5\n",
      "Diego Da Silva Costa 1\n",
      "Romelu Lukaku 2\n",
      "Abel Hernández 5\n",
      "Jamie Vardy 5\n",
      "Shinji Okazaki 5\n",
      "Christian Benteke 4\n",
      "Daniel Sturridge 5\n",
      "Divock Origi 5\n",
      "Sergio Agüero 1\n",
      "Wayne Rooney 1\n",
      "Marcus Rashford 5\n",
      "Zlatan Ibrahimovic 1\n",
      "Cristhian Stuani 5\n",
      "Shane Long 5\n",
      "Peter Crouch 3\n",
      "Fabio Borini 5\n",
      "Jermain Defoe 5\n",
      "Harry Kane 1\n",
      "Vincent Janssen 5\n",
      "Troy Deeney 1\n",
      "Salomón Rondón 5\n",
      "Enner Valencia 5\n",
      "Álvaro Negredo 5\n",
      "Fernando Llorente 4\n",
      "Stefano Okaka 5\n",
      "Islam Slimani 5\n"
     ]
    }
   ],
   "source": [
    "makePredictions(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
