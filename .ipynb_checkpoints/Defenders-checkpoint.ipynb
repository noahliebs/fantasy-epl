{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML on Defenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_forward_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                         'minutes', 'successful_dribbles', 'own_goals', 'interception_total', \n",
    "                         'goals_scored', 'key_passes', 'accurateCrosses_total', 'aerialWon_total', 'assists', \n",
    "                         'points_above_replacement', 'name', 'age', 'ontarget_scoring_att', 'next_year']\n",
    "\n",
    "relevant_midfield_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                          'minutes', 'successful_dribbles', 'own_goals', 'interception_total', 'ontarget_scoring_att',\n",
    "                          'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', 'aerialWon_total', \n",
    "                          'assists', 'points_above_replacement', 'name', 'age', 'next_year']\n",
    "\n",
    "relevant_defense_keys = ['goals_conceded', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total',\n",
    "                         'red_cards', 'minutes', 'successful_dribbles', 'own_goals', 'name', 'ontarget_scoring_att',\n",
    "                         'interception_total', 'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', \n",
    "                         'aerialWon_total', 'assists', 'points_above_replacement', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "relevant_goalie_keys = ['goals_conceded', 'saves', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'red_cards', \n",
    "                        'minutes', 'own_goals', 'interception_total', 'key_passes', 'clean_sheets', 'aerialWon_total', \n",
    "                        'penalties_saved', 'points_above_replacement', 'name', 'clearance_total', 'age', 'next_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"Data/positional.json\", \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "#We will do analysis on Defenders\n",
    "position = '2'\n",
    "players = []\n",
    "for player in data[position]:\n",
    "    players.append(pd.DataFrame([player['history']['2015/16']]))\n",
    "    players.append(pd.DataFrame([player['history']['2014/15']]))\n",
    "    players.append(pd.DataFrame([player['history']['2013/14']]))\n",
    "    players.append(pd.DataFrame([player['history']['2012/13']]))\n",
    "\n",
    "players = pd.concat(players)\n",
    "filter = players['togga_score'] > 0\n",
    "players = players[filter]\n",
    "keys = relevant_defense_keys.copy()\n",
    "keys.remove('points_above_replacement')\n",
    "players = players[keys]\n",
    "players = players.dropna(axis=1,how='all')\n",
    "players = players.dropna(axis=0,how='any')\n",
    "\n",
    "players = players.set_index(\"name\")\n",
    "players.index.name = None\n",
    "keys.remove('name')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# box and whisker plots of some of the stats\n",
    "plot_keys = ['togga_score', 'goals_scored', 'assists', 'ontarget_scoring_att', 'aerialWon_total', 'minutes', \n",
    "             'successful_dribbles', 'age', 'next_year']\n",
    "players[plot_keys].plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "players[plot_keys].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.8588994987071\n"
     ]
    }
   ],
   "source": [
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "X = players[x_keys]\n",
    "Y = players['next_year']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=324)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_prediction = regressor.predict(X_test)\n",
    "#X_test, y_prediction\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = Y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.68400986095443\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_prediction = regressor.predict(X_test)\n",
    "#y_prediction\n",
    "#X_train.head()\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.336250 (0.102504)\n",
      "LDA: 0.355000 (0.078102)\n",
      "KNN: 0.315833 (0.077478)\n",
      "CART: 0.361667 (0.078125)\n",
      "NB: 0.315000 (0.121209)\n",
      "SVM: 0.412500 (0.133814)\n"
     ]
    }
   ],
   "source": [
    "players[\"category\"] = players[\"togga_score\"]\n",
    "for index, row in players.iterrows():\n",
    "    if row['next_year'] > 0:\n",
    "        ratio = row['togga_score'] / abs(row['next_year'])\n",
    "        if  ratio < 0.8:\n",
    "            val = -1\n",
    "        elif ratio < 1.2:\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 1\n",
    "        #print(ratio,val)\n",
    "    else:\n",
    "        #row[x_keys] = 0\n",
    "        #forwards.drop(index, inplace=True)\n",
    "        val = -10\n",
    "    players.set_value(index,'category',val)\n",
    "\n",
    "    \n",
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "x_keys.append(\"category\")\n",
    "filter = players['next_year'] > 0\n",
    "players = players[filter]\n",
    "array = players[x_keys].values\n",
    "X = array[:,:-1]\n",
    "Y = array[:,-1].astype(int)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(len(X_train), n_folds=10, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for player in data[position]:\n",
    "    new_data.append(pd.DataFrame([player['history']['2016/17']]))\n",
    "\n",
    "new_data = pd.concat(new_data)\n",
    "filter = new_data['togga_score'] > 0\n",
    "new_data = new_data[filter]\n",
    "new_data = new_data.dropna(axis=1,how='all')\n",
    "\n",
    "All_predictions = []\n",
    "All_predictions.append(new_data['name'].values.astype('str'))\n",
    "new_data = new_data.set_index(\"name\")\n",
    "new_data.index.name = None\n",
    "new_keys = keys.copy()\n",
    "new_keys.remove('next_year')\n",
    "new_data = new_data[new_keys]\n",
    "new_data = new_data.dropna(axis=0,how='any')\n",
    "new_X = new_data.values\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "def makePredictions(model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "    print(accuracy_score(Y_validation, predictions))\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "    predictions = model.predict(new_X)\n",
    "    #for name, pred in zip(new_data.index.values, predictions):\n",
    "        #print(name,pred)\n",
    "    All_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.307692307692\n",
      "[[0 1 1 1]\n",
      " [0 4 3 3]\n",
      " [2 5 6 4]\n",
      " [1 4 2 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         3\n",
      "         -1       0.29      0.40      0.33        10\n",
      "          0       0.50      0.35      0.41        17\n",
      "          1       0.20      0.22      0.21         9\n",
      "\n",
      "avg / total       0.34      0.31      0.31        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538461538462\n",
      "[[ 1  0  2  0]\n",
      " [ 0  7  3  0]\n",
      " [ 0  2 10  5]\n",
      " [ 0  1  5  3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       1.00      0.33      0.50         3\n",
      "         -1       0.70      0.70      0.70        10\n",
      "          0       0.50      0.59      0.54        17\n",
      "          1       0.38      0.33      0.35         9\n",
      "\n",
      "avg / total       0.56      0.54      0.54        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282051282051\n",
      "[[1 1 1 0]\n",
      " [3 2 3 2]\n",
      " [7 1 6 3]\n",
      " [2 1 4 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.08      0.33      0.12         3\n",
      "         -1       0.40      0.20      0.27        10\n",
      "          0       0.43      0.35      0.39        17\n",
      "          1       0.29      0.22      0.25         9\n",
      "\n",
      "avg / total       0.36      0.28      0.30        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.564102564103\n",
      "[[ 0  0  3  0]\n",
      " [ 0  7  3  0]\n",
      " [ 0  2 12  3]\n",
      " [ 0  1  5  3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         3\n",
      "         -1       0.70      0.70      0.70        10\n",
      "          0       0.52      0.71      0.60        17\n",
      "          1       0.50      0.33      0.40         9\n",
      "\n",
      "avg / total       0.52      0.56      0.53        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "makePredictions(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358974358974\n",
      "[[1 1 1 0]\n",
      " [0 3 4 3]\n",
      " [1 4 8 4]\n",
      " [0 2 5 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.50      0.33      0.40         3\n",
      "         -1       0.30      0.30      0.30        10\n",
      "          0       0.44      0.47      0.46        17\n",
      "          1       0.22      0.22      0.22         9\n",
      "\n",
      "avg / total       0.36      0.36      0.36        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.435897435897\n",
      "[[ 0  0  3  0]\n",
      " [ 0  0 10  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  9  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         3\n",
      "         -1       0.00      0.00      0.00        10\n",
      "          0       0.44      1.00      0.61        17\n",
      "          1       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.19      0.44      0.26        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "makePredictions(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "chain = chain.from_iterable(zip(*All_predictions))\n",
    "preds = list(chain)\n",
    "all_preds = 'Name\\tCART\\tLDA\\tGNB\\tLR\\tKNN\\tSVC\\n'\n",
    "for i in range(int(len(preds)/7)):\n",
    "    #print(preds[i*7], preds[i*7+1:i*7+7])\n",
    "    all_preds+=(preds[i*7])\n",
    "    for j in range(i*7+1, i*7+7):\n",
    "        all_preds+='\\t' + str(preds[j])\n",
    "    all_preds+='\\n'\n",
    "#print(all_preds) \n",
    "all_preds.encode(\"utf-8\")\n",
    "with open(\"Data/Predictions/Defense.txt\", \"w\") as f:\n",
    "    f.write(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "txt_file = r\"Data/Predictions/Defense.txt\"\n",
    "csv_file = r\"Data/Predictions/Defense.csv\"\n",
    "\n",
    "in_txt = csv.reader(open(txt_file, \"r\"), delimiter = '\\t')\n",
    "out_csv = csv.writer(open(csv_file, 'w', newline=''))\n",
    "out_csv.writerows(in_txt)\n",
    "del out_csv\n",
    "del in_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
