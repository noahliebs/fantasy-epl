{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML on Midfielders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_forward_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                         'minutes', 'successful_dribbles', 'own_goals', 'interception_total', \n",
    "                         'goals_scored', 'key_passes', 'accurateCrosses_total', 'aerialWon_total', 'assists', \n",
    "                         'points_above_replacement', 'name', 'age', 'ontarget_scoring_att', 'next_year']\n",
    "\n",
    "relevant_midfield_keys = ['togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total', 'red_cards', \n",
    "                          'minutes', 'successful_dribbles', 'own_goals', 'interception_total', 'ontarget_scoring_att',\n",
    "                          'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', 'aerialWon_total', \n",
    "                          'assists', 'points_above_replacement', 'name', 'age', 'next_year']\n",
    "\n",
    "relevant_defense_keys = ['goals_conceded', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'dispossessed_total',\n",
    "                         'red_cards', 'minutes', 'successful_dribbles', 'own_goals', 'name', 'ontarget_scoring_att',\n",
    "                         'interception_total', 'goals_scored', 'key_passes', 'accurateCrosses_total', 'clean_sheets', \n",
    "                         'aerialWon_total', 'assists', 'points_above_replacement', 'clearance_total', 'age', 'next_year']\n",
    "\n",
    "relevant_goalie_keys = ['goals_conceded', 'saves', 'togga_score', 'apps', 'tackle_total', 'yellow_cards', 'red_cards', \n",
    "                        'minutes', 'own_goals', 'interception_total', 'key_passes', 'clean_sheets', 'aerialWon_total', \n",
    "                        'penalties_saved', 'points_above_replacement', 'name', 'clearance_total', 'age', 'next_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"Data/positional.json\", \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "#We will do analysis on Midfielders\n",
    "position = '3'\n",
    "players = []\n",
    "for player in data[position]:\n",
    "    players.append(pd.DataFrame([player['history']['2015/16']]))\n",
    "    players.append(pd.DataFrame([player['history']['2014/15']]))\n",
    "    players.append(pd.DataFrame([player['history']['2013/14']]))\n",
    "    players.append(pd.DataFrame([player['history']['2012/13']]))\n",
    "\n",
    "players = pd.concat(players)\n",
    "filter = players['togga_score'] > 0\n",
    "players = players[filter]\n",
    "keys = relevant_midfield_keys.copy()\n",
    "keys.remove('points_above_replacement')\n",
    "players = players[keys]\n",
    "players = players.dropna(axis=1,how='all')\n",
    "players = players.dropna(axis=0,how='any')\n",
    "\n",
    "players = players.set_index(\"name\")\n",
    "players.index.name = None\n",
    "keys.remove('name')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# box and whisker plots of some of the stats\n",
    "plot_keys = ['togga_score', 'goals_scored', 'assists', 'ontarget_scoring_att', 'aerialWon_total', 'minutes', \n",
    "             'successful_dribbles', 'age', 'next_year']\n",
    "players[plot_keys].plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "players[plot_keys].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.52295927141816\n"
     ]
    }
   ],
   "source": [
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "X = players[x_keys]\n",
    "Y = players['next_year']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=324)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_prediction = regressor.predict(X_test)\n",
    "#X_test, y_prediction\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = Y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203.022851346872\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_prediction = regressor.predict(X_test)\n",
    "#y_prediction\n",
    "#X_train.head()\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(y_true = Y_test, y_pred = y_prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.375500 (0.085095)\n",
      "LDA: 0.379667 (0.089476)\n",
      "KNN: 0.388167 (0.073119)\n",
      "CART: 0.388500 (0.094556)\n",
      "NB: 0.384167 (0.082369)\n",
      "SVM: 0.417500 (0.094243)\n"
     ]
    }
   ],
   "source": [
    "players[\"category\"] = players[\"togga_score\"]\n",
    "for index, row in players.iterrows():\n",
    "    if row['next_year'] > 0:\n",
    "        ratio = row['togga_score'] / abs(row['next_year'])\n",
    "        if  ratio < 0.8:\n",
    "            val = -1\n",
    "        elif ratio < 1.2:\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 1\n",
    "        #print(ratio,val)\n",
    "    else:\n",
    "        #row[x_keys] = 0\n",
    "        #forwards.drop(index, inplace=True)\n",
    "        val = -10\n",
    "    players.set_value(index,'category',val)\n",
    "\n",
    "    \n",
    "x_keys = keys.copy()\n",
    "x_keys.remove('next_year')\n",
    "x_keys.append(\"category\")\n",
    "filter = players['next_year'] > 0\n",
    "players = players[filter]\n",
    "array = players[x_keys].values\n",
    "X = array[:,:-1]\n",
    "Y = array[:,-1].astype(int)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(len(X_train), n_folds=10, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for player in data[position]:\n",
    "    new_data.append(pd.DataFrame([player['history']['2016/17']]))\n",
    "\n",
    "new_data = pd.concat(new_data)\n",
    "filter = new_data['togga_score'] > 0\n",
    "new_data = new_data[filter]\n",
    "new_data = new_data.dropna(axis=1,how='all')\n",
    "\n",
    "All_predictions = []\n",
    "All_predictions.append(new_data['name'].values.astype('str'))\n",
    "new_data = new_data.set_index(\"name\")\n",
    "new_data.index.name = None\n",
    "new_keys = keys.copy()\n",
    "new_keys.remove('next_year')\n",
    "new_data = new_data[new_keys]\n",
    "new_data = new_data.dropna(axis=0,how='any')\n",
    "new_X = new_data.values\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "def makePredictions(model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "    print(accuracy_score(Y_validation, predictions))\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "    predictions = model.predict(new_X)\n",
    "    #for name, pred in zip(new_data.index.values, predictions):\n",
    "        #print(name,pred)\n",
    "    All_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.426229508197\n",
      "[[ 0  1  0  1]\n",
      " [ 0  6  4  5]\n",
      " [ 0  2 14 10]\n",
      " [ 3  3  6  6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.50      0.40      0.44        15\n",
      "          0       0.58      0.54      0.56        26\n",
      "          1       0.27      0.33      0.30        18\n",
      "\n",
      "avg / total       0.45      0.43      0.44        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327868852459\n",
      "[[ 0  0  0  2]\n",
      " [ 1  2  4  8]\n",
      " [ 0  7  8 11]\n",
      " [ 0  4  4 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.15      0.13      0.14        15\n",
      "          0       0.50      0.31      0.38        26\n",
      "          1       0.32      0.56      0.41        18\n",
      "\n",
      "avg / total       0.35      0.33      0.32        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.377049180328\n",
      "[[ 0  1  0  1]\n",
      " [ 2  3  6  4]\n",
      " [ 3  3  9 11]\n",
      " [ 1  2  4 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.33      0.20      0.25        15\n",
      "          0       0.47      0.35      0.40        26\n",
      "          1       0.41      0.61      0.49        18\n",
      "\n",
      "avg / total       0.40      0.38      0.38        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311475409836\n",
      "[[ 0  0  0  2]\n",
      " [ 1  1  4  9]\n",
      " [ 0  5  9 12]\n",
      " [ 1  4  4  9]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.10      0.07      0.08        15\n",
      "          0       0.53      0.35      0.42        26\n",
      "          1       0.28      0.50      0.36        18\n",
      "\n",
      "avg / total       0.33      0.31      0.30        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "makePredictions(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327868852459\n",
      "[[ 0  1  0  1]\n",
      " [ 0  4  5  6]\n",
      " [ 0  8 10  8]\n",
      " [ 0  7  5  6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.20      0.27      0.23        15\n",
      "          0       0.50      0.38      0.43        26\n",
      "          1       0.29      0.33      0.31        18\n",
      "\n",
      "avg / total       0.35      0.33      0.33        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "makePredictions(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.295081967213\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 26]\n",
      " [ 0  0  0 18]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -10       0.00      0.00      0.00         2\n",
      "         -1       0.00      0.00      0.00        15\n",
      "          0       0.00      0.00      0.00        26\n",
      "          1       0.30      1.00      0.46        18\n",
      "\n",
      "avg / total       0.09      0.30      0.13        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "makePredictions(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "chain = chain.from_iterable(zip(*All_predictions))\n",
    "preds = list(chain)\n",
    "all_preds = 'Name\\tCART\\tLDA\\tGNB\\tLR\\tKNN\\tSVC\\n'\n",
    "for i in range(int(len(preds)/7)):\n",
    "    #print(preds[i*7], preds[i*7+1:i*7+7])\n",
    "    all_preds+=(preds[i*7])\n",
    "    for j in range(i*7+1, i*7+7):\n",
    "        all_preds+='\\t' + str(preds[j])\n",
    "    all_preds+='\\n'\n",
    "#print(all_preds) \n",
    "all_preds.encode(\"utf-8\")\n",
    "with open(\"Data/Predictions/Midfield.txt\", \"w\") as f:\n",
    "    f.write(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "txt_file = r\"Data/Predictions/Midfield.txt\"\n",
    "csv_file = r\"Data/Predictions/Midfield.csv\"\n",
    "\n",
    "in_txt = csv.reader(open(txt_file, \"r\"), delimiter = '\\t')\n",
    "out_csv = csv.writer(open(csv_file, 'w', newline=''))\n",
    "out_csv.writerows(in_txt)\n",
    "del out_csv\n",
    "del in_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
